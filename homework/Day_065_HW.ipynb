{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day_065"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 練習時間 \n",
    "嘗試調整參數:  \n",
    "sg：sg = 1 表示採用 skip-gram, sg = 0 表示採用 cbow  \n",
    "window：能往左往右看幾個字的意思 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import gensim, logging\n",
    "from gensim.models import word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logging.basicConfig(format = '%(asctime)s : %(levelname)s : %(message)s', level = logging.INFO)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentences = [['I am a hero', 'sentence'], ['She is a teacher', 'sentence']] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trainModel (sg, window):\n",
    "    # train word2vec on the two sentences  \n",
    "    model = word2vec.Word2Vec(sentences, size = 256, min_count = 1, window = window, workers = 4, sg = sg)  \n",
    "    return model\n",
    "    # sg = 0 表示 COBW, sg = 1 表示 skip-gram    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-03-10 20:06:47,479 : INFO : collecting all words and their counts\n",
      "2019-03-10 20:06:47,481 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2019-03-10 20:06:47,483 : INFO : collected 3 word types from a corpus of 4 raw words and 2 sentences\n",
      "2019-03-10 20:06:47,485 : INFO : Loading a fresh vocabulary\n",
      "2019-03-10 20:06:47,487 : INFO : min_count=1 retains 3 unique words (100% of original 3, drops 0)\n",
      "2019-03-10 20:06:47,489 : INFO : min_count=1 leaves 4 word corpus (100% of original 4, drops 0)\n",
      "2019-03-10 20:06:47,491 : INFO : deleting the raw counts dictionary of 3 items\n",
      "2019-03-10 20:06:47,493 : INFO : sample=0.001 downsamples 3 most-common words\n",
      "2019-03-10 20:06:47,495 : INFO : downsampling leaves estimated 0 word corpus (5.7% of prior 4)\n",
      "2019-03-10 20:06:47,497 : INFO : estimated required memory for 3 words and 256 dimensions: 7644 bytes\n",
      "2019-03-10 20:06:47,498 : INFO : resetting layer weights\n",
      "2019-03-10 20:06:47,500 : INFO : training model with 4 workers on 3 vocabulary and 256 features, using sg=0 hs=0 sample=0.001 negative=5 window=7\n",
      "2019-03-10 20:06:47,505 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-03-10 20:06:47,507 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-03-10 20:06:47,509 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-03-10 20:06:47,510 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-03-10 20:06:47,512 : INFO : EPOCH - 1 : training on 4 raw words (0 effective words) took 0.0s, 0 effective words/s\n",
      "2019-03-10 20:06:47,517 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-03-10 20:06:47,518 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-03-10 20:06:47,520 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-03-10 20:06:47,522 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-03-10 20:06:47,523 : INFO : EPOCH - 2 : training on 4 raw words (0 effective words) took 0.0s, 0 effective words/s\n",
      "2019-03-10 20:06:47,538 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-03-10 20:06:47,539 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-03-10 20:06:47,541 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-03-10 20:06:47,543 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-03-10 20:06:47,546 : INFO : EPOCH - 3 : training on 4 raw words (1 effective words) took 0.0s, 109 effective words/s\n",
      "2019-03-10 20:06:47,557 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-03-10 20:06:47,558 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-03-10 20:06:47,560 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-03-10 20:06:47,561 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-03-10 20:06:47,563 : INFO : EPOCH - 4 : training on 4 raw words (0 effective words) took 0.0s, 0 effective words/s\n",
      "2019-03-10 20:06:47,568 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-03-10 20:06:47,569 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-03-10 20:06:47,571 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-03-10 20:06:47,574 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-03-10 20:06:47,576 : INFO : EPOCH - 5 : training on 4 raw words (0 effective words) took 0.0s, 0 effective words/s\n",
      "2019-03-10 20:06:47,577 : INFO : training on a 20 raw words (1 effective words) took 0.1s, 13 effective words/s\n",
      "2019-03-10 20:06:47,579 : WARNING : under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec(vocab=3, size=256, alpha=0.025)\n"
     ]
    }
   ],
   "source": [
    "model = trainModel(sg = 0, window = 7)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `similarity` (Method will be removed in 4.0.0, use self.wv.similarity() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.04923852835635777"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.similarity('I am a hero', 'She is a teacher')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-03-10 20:06:48,591 : INFO : saving Word2Vec object under mymodel, separately None\n",
      "2019-03-10 20:06:48,593 : INFO : not storing attribute vectors_norm\n",
      "2019-03-10 20:06:48,597 : INFO : not storing attribute cum_table\n",
      "2019-03-10 20:06:48,608 : INFO : saved mymodel\n",
      "2019-03-10 20:06:48,609 : INFO : loading Word2Vec object from mymodel\n",
      "2019-03-10 20:06:48,612 : INFO : loading wv recursively from mymodel.wv.* with mmap=None\n",
      "2019-03-10 20:06:48,614 : INFO : setting ignored attribute vectors_norm to None\n",
      "2019-03-10 20:06:48,615 : INFO : loading vocabulary recursively from mymodel.vocabulary.* with mmap=None\n",
      "2019-03-10 20:06:48,617 : INFO : loading trainables recursively from mymodel.trainables.* with mmap=None\n",
      "2019-03-10 20:06:48,619 : INFO : setting ignored attribute cum_table to None\n",
      "2019-03-10 20:06:48,620 : INFO : loaded mymodel\n"
     ]
    }
   ],
   "source": [
    "model.save('mymodel')  \n",
    "new_model = gensim.models.Word2Vec.load('mymodel')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-03-10 20:06:49,271 : INFO : collecting all words and their counts\n",
      "2019-03-10 20:06:49,273 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2019-03-10 20:06:49,275 : INFO : collected 3 word types from a corpus of 4 raw words and 2 sentences\n",
      "2019-03-10 20:06:49,277 : INFO : Loading a fresh vocabulary\n",
      "2019-03-10 20:06:49,279 : INFO : min_count=1 retains 3 unique words (100% of original 3, drops 0)\n",
      "2019-03-10 20:06:49,280 : INFO : min_count=1 leaves 4 word corpus (100% of original 4, drops 0)\n",
      "2019-03-10 20:06:49,282 : INFO : deleting the raw counts dictionary of 3 items\n",
      "2019-03-10 20:06:49,284 : INFO : sample=0.001 downsamples 3 most-common words\n",
      "2019-03-10 20:06:49,286 : INFO : downsampling leaves estimated 0 word corpus (5.7% of prior 4)\n",
      "2019-03-10 20:06:49,289 : INFO : estimated required memory for 3 words and 256 dimensions: 7644 bytes\n",
      "2019-03-10 20:06:49,291 : INFO : resetting layer weights\n",
      "2019-03-10 20:06:49,293 : INFO : training model with 4 workers on 3 vocabulary and 256 features, using sg=1 hs=0 sample=0.001 negative=5 window=6\n",
      "2019-03-10 20:06:49,299 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-03-10 20:06:49,300 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-03-10 20:06:49,302 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-03-10 20:06:49,304 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-03-10 20:06:49,305 : INFO : EPOCH - 1 : training on 4 raw words (0 effective words) took 0.0s, 0 effective words/s\n",
      "2019-03-10 20:06:49,310 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-03-10 20:06:49,312 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-03-10 20:06:49,313 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-03-10 20:06:49,315 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-03-10 20:06:49,318 : INFO : EPOCH - 2 : training on 4 raw words (0 effective words) took 0.0s, 0 effective words/s\n",
      "2019-03-10 20:06:49,336 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-03-10 20:06:49,339 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-03-10 20:06:49,340 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-03-10 20:06:49,343 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-03-10 20:06:49,345 : INFO : EPOCH - 3 : training on 4 raw words (1 effective words) took 0.0s, 99 effective words/s\n",
      "2019-03-10 20:06:49,351 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-03-10 20:06:49,353 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-03-10 20:06:49,354 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-03-10 20:06:49,357 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-03-10 20:06:49,359 : INFO : EPOCH - 4 : training on 4 raw words (0 effective words) took 0.0s, 0 effective words/s\n",
      "2019-03-10 20:06:49,364 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-03-10 20:06:49,365 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-03-10 20:06:49,367 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-03-10 20:06:49,369 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-03-10 20:06:49,370 : INFO : EPOCH - 5 : training on 4 raw words (0 effective words) took 0.0s, 0 effective words/s\n",
      "2019-03-10 20:06:49,372 : INFO : training on a 20 raw words (1 effective words) took 0.1s, 13 effective words/s\n",
      "2019-03-10 20:06:49,373 : WARNING : under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec(vocab=3, size=256, alpha=0.025)\n"
     ]
    }
   ],
   "source": [
    "model2 = trainModel(1, 6)\n",
    "print(model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `similarity` (Method will be removed in 4.0.0, use self.wv.similarity() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.04923852835635777"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.similarity('I am a hero', 'She is a teacher')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-03-10 20:06:52,214 : INFO : saving Word2Vec object under mymode2, separately None\n",
      "2019-03-10 20:06:52,217 : INFO : not storing attribute vectors_norm\n",
      "2019-03-10 20:06:52,219 : INFO : not storing attribute cum_table\n",
      "2019-03-10 20:06:52,235 : INFO : saved mymode2\n",
      "2019-03-10 20:06:52,236 : INFO : loading Word2Vec object from mymode2\n",
      "2019-03-10 20:06:52,239 : INFO : loading wv recursively from mymode2.wv.* with mmap=None\n",
      "2019-03-10 20:06:52,240 : INFO : setting ignored attribute vectors_norm to None\n",
      "2019-03-10 20:06:52,241 : INFO : loading vocabulary recursively from mymode2.vocabulary.* with mmap=None\n",
      "2019-03-10 20:06:52,243 : INFO : loading trainables recursively from mymode2.trainables.* with mmap=None\n",
      "2019-03-10 20:06:52,244 : INFO : setting ignored attribute cum_table to None\n",
      "2019-03-10 20:06:52,246 : INFO : loaded mymode2\n"
     ]
    }
   ],
   "source": [
    "model.save('mymode2')  \n",
    "new_model = gensim.models.Word2Vec.load('mymode2')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
